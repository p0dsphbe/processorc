国外计算机科学经典教材数据挖掘原理(第3版)/(英)麦克斯.布拉默 PDF下载 [英]麦克斯·布拉默MaxBramer 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#730252681
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#730252681
<p>书名:国外计算机科学经典教材数据挖掘原理(第3版)/(英)麦克斯.布拉默</p><p>作者:[英]麦克斯·布拉默Max Bramer</p><p>页数:423</p><p>定价:¥79.8</p><p>出版社:清华大学出版社</p><p>出版日期:2019-09-01</p><p>ISBN:9787302526810</p><p><h2>本书特色</h2></p>[<p>
      《数据挖掘原理(第3版)》深入探讨重要的数据挖掘技术。所谓数据挖掘，即从数据中自动提取隐含和潜在有用的信息；该技术正越来越多地用于商业、科学和其他应用领域。本书浓墨重彩地描述分类、关联规则挖掘和聚类。 　　
        普通读者可通过本书自学数据挖掘“黑匣子”内部的基本原理，并了解如何合理地选择商业数据挖掘包。学者和资深科研人员可通过本书了解*前沿技术并进一步推动该领域的发展。 　　
        《数据挖掘原理(第3版)》在第2版的基础上进行扩展，透彻讲解适用于平稳数据的H-Tree算法，以及适用于时间相关数据(概念漂移)的CDH-Tree算法。
                                        </p>]<p><h2>内容简介</h2></p>[<p>《数据挖掘原理(第3版)》深入探讨重要的数据挖掘技术。所谓数据挖掘，即从数据中自动提取隐含和潜在有用的信息；该技术正越来越多地用于商业、科学和其他应用领域。本书浓墨重彩地描述分类、关联规则挖掘和聚类。
    普通读者可通过本书自学数据挖掘“黑匣子”内部的基本原理，并了解如何合理地选择商业数据挖掘包。学者和资深科研人员可通过本书了解很前沿技术并进一步推动该领域的发展。
    本书在第2版的基础上进行扩展，透彻讲解适用于平稳数据的H-Tree算法，以及适用于时间相关数据(概念漂移)的CDH-Tree算法。</p>]<p><h2>作者简介</h2></p>[<p>        Max Bramer是英国朴次茅斯大学信息技术系荣誉教授、IFIP副主席、英国计算机学会AI专家组主席。
<br/>　　自从 “数据挖掘”“数据库中的知识发现”“大数据”和“预测分析”等技术兴起以来，Max积极参与了多个数据挖掘项目，尤其是与数据自动分类相关的项目。
        Max发表了大量技术文章，曾撰写Research and Development in Intelligent Systems等著作。Max具有多年的本科和研究生教学经验。</p>]<p><h2>目录</h2></p>
    目    录 第 1 章  数据挖掘简介   11.1  数据爆炸   11.2  知识发现   21.3  数据挖掘的应用   31.4  标签和无标签数据   41.5  监督学习：分类   41.6  监督学习：数值预测   51.7  无监督学习：关联规则   61.8  无监督学习：聚类   7第 2 章  用于挖掘的数据   92.1  标准制定   92.2  变量的类型   102.3  数据准备   112.4  缺失值   132.4.1  丢弃实例   132.4.2  用*频繁值/平均值替换   132.5  减少属性个数   142.6  数据集的UCI存储库   152.7  本章小结   152.8  自我评估练习   15第 3 章  分类简介：朴素贝叶斯和*近邻算法   173.1  什么是分类   173.2  朴素贝叶斯分类器   183.3  *近邻分类   243.3.1  距离测量   263.3.2  标准化   283.3.3  处理分类属性   293.4  急切式和懒惰式学习   303.5  本章小结   303.6  自我评估练习   30第 4 章  使用决策树进行分类   314.1  决策规则和决策树   314.1.1  决策树：高尔夫示例   314.1.2  术语   334.1.3  degrees数据集   334.2  TDIDT算法   364.3  推理类型   384.4  本章小结   384.5  自我评估练习   39第 5 章  决策树归纳：使用熵进行属性选择   415.1  属性选择：一个实验   415.2  替代决策树   425.2.1  足球/无板篮球示例   425.2.2  匿名数据集   445.3  选择要分裂的属性：使用熵   465.3.1  lens24数据集   465.3.2  熵   475.3.3  使用熵进行属性选择   485.3.4  信息增益*大化   505.4  本章小结   515.5  自我评估练习   51第 6 章  决策树归纳：使用频率表进行属性选择   536.1  实践中的熵计算   536.1.1  等效性证明   556.1.2  关于零值的说明   566.2  其他属性选择标准：多样性基尼指数   566.3  χ2属性选择准则   576.4  归纳偏好   606.5  使用增益比进行属性选择   616.5.1  分裂信息的属性   626.5.2  总结   636.6  不同属性选择标准生成的规则数   636.7  缺失分支   646.8  本章小结   656.9  自我评估练习   65第 7 章  估计分类器的预测精度   677.1  简介   677.2  方法1：将数据划分为训练集和测试集   687.2.1  标准误差   687.2.2  重复训练和测试   697.3  方法2：k-折交叉验证   707.4  方法3：N -折交叉验证   707.5  实验结果I   717.6  实验结果II：包含缺失值的数据集   737.6.1  策略1：丢弃实例   737.6.2  策略2：用*频繁值/平均值替换   747.6.3  类别缺失   757.7  混淆矩阵   757.8  本章小结   777.9  自我评估练习   77第 8 章  连续属性   798.1  简介   798.2  局部与全局离散化   818.3  向TDIDT添加局部离散化   818.3.1  计算一组伪属性的信息增益   828.3.2  计算效率   868.4  使用ChiMerge算法进行全局离散化   888.4.1  计算期望值和χ2   908.4.2  查找阈值   948.4.3  设置minIntervals和maxIntervals   958.4.4  ChiMerge算法：总结   968.4.5  对ChiMerge算法的评述   968.5  比较树归纳法的全局离散化和局部离散化   978.6  本章小结   988.7  自我评估练习   98第 9 章  避免决策树的过度拟合   999.1  处理训练集中的冲突   999.2  关于过度拟合数据的更多规则   1039.3  预剪枝决策树   1049.4  后剪枝决策树   1069.5  本章小结   1119.6  自我评估练习   111第 10 章  关于熵的更多信息   11310.1  简介   11310.2  使用位的编码信息   11610.3  区分值   11710.4  对“非等可能”的值进行编码   11810.5  训练集的熵   12110.6  信息增益必须为正数或零   12210.7  使用信息增益来简化分类任务的特征   12310.7.1  示例1：genetics数据集   12410.7.2  示例2：bcst96数据集   12610.8  本章小结   12810.9  自我评估练习   128第 11 章  归纳分类的模块化规则   12911.1  规则后剪枝   12911.2  冲突解决   13011.3  决策树的问题   13311.4  Prism算法   13511.4.1  基本Prism算法的变化   14111.4.2  将Prism算法与TDIDT算法进行比较   14211.5  本章小结   14311.6  自我评估练习   143第 12 章  度量分类器的性能   14512.1  真假正例和真假负例   14612.2  性能度量   14712.3  真假正例率与预测精度   15012.4  ROC图   15112.5  ROC曲线   15312.6  寻找*佳分类器   15312.7  本章小结   15512.8  自我评估练习   155第 13 章  处理大量数据   15713.1  简介   15713.2  将数据分发到多个处理器   15913.3  案例研究：PMCRI   16113.4  评估分布式系统PMCRI的有效性   16313.5  逐步修改分类器   16713.6  本章小结   17113.7  自我评估练习   171第 14 章  集成分类   17314.1  简介   17314.2  估计分类器的性能   17514.3  为每个分类器选择不同的训练集   17614.4  为每个分类器选择一组不同的属性   17714.5  组合分类：替代投票系统   17714.6  并行集成分类器   18014.7  本章小结   18114.8  自我评估练习   181第 15 章  比较分类器   18315.1  简介   18315.2  配对t检验   18415.3  为比较评估选择数据集   18915.4  抽样   19115.5  “无显著差异”的结果有多糟糕?   19315.6  本章小结   19415.7  自我评估练习   194第 16 章  关联规则挖掘I   19516.1  简介   19516.2  规则兴趣度的衡量标准   19616.2.1  Piatetsky-Shapiro标准和RI度量   19816.2.2  规则兴趣度度量应用于chess数据集   20016.2.3  使用规则兴趣度度量来解决冲突   20116.3  关联规则挖掘任务   20216.4  找到*佳N条规则   20216.4.1  J-Measure：度量规则的信息内容   20316.4.2  搜索策略   20416.5  本章小结   20716.6  自我评估练习   207第 17 章  关联规则挖掘II   20917.1  简介   20917.2  事务和项目集   20917.3  对项目集的支持   21117.4  关联规则   21117.5  生成关联规则   21317.6  Apriori   21417.7  生成支持项目集：一个示例   21717.8  为支持项目集生成规则   21917.9  规则兴趣度度量：提升度和杠杆率   22017.10  本章小结   22217.11  自我评估练习   222第 18 章  关联规则挖掘III：频繁模式树   22518.1  简介：FP-growth   22518.2  构造FP-tree   22718.2.1  预处理事务数据库   22718.2.2  初始化   22918.2.3  处理事务1：f, c, a, m, p   23018.2.4  处理事务2：f, c, a, b, m   23118.2.5  处理事务3：f, b   23518.2.6  处理事务4：c, b, p   23618.2.7  处理事务5：f, c, a, m, p   23618.3  从FP-tree中查找频繁项目集   23818.3.1  以项目p结尾的项目集   24018.3.2  以项目m结尾的项目集   24818.4  本章小结   25418.5  自我评估练习   254第 19 章  聚类   25519.1  简介   25519.2  k-means聚类   25719.2.1  示例   25819.2.2  找到*佳簇集   26219.3  凝聚式层次聚类   26319.3.1  记录簇间距离   26519.3.2  终止聚类过程   26819.4  本章小结   26819.5  自我评估练习   268第 20 章  文本挖掘   26920.1  多重分类   26920.2  表示数据挖掘的文本文档   27020.3  停用词和词干   27120.4  使用信息增益来减少特征   27220.5  表示文本文档：构建向量空间模型   27220.6  规范权重   27320.7  测量两个向量之间的距离   27420.8  度量文本分类器的性能   27520.9  超文本分类   27520.9.1  对网页进行分类   27620.9.2  超文本分类与文本分类   27720.10  本章小结   27920.11  自我评估练习   280第 21 章  分类流数据   28121.1  简介   28121.2  构建H-Tree：更新数组   28321.2.1  currentAtts数组   28421.2.2  splitAtt数组   28421.2.3  将记录排序到适当的叶节点   28421.2.4  hitcount数组   28521.2.5  classtotals数组   28521.2.6  acvCounts阵列   28521.2.7  branch数组   28621.3  构建H-Tree：详细示例   28721.3.1  步骤1：初始化根节点0   28721.3.2  步骤2：开始读取记录   28721.3.3  步骤3：考虑在节点0处分裂   28821.3.4  步骤4：在根节点上拆分并初始化新的叶节点   28921.3.5  步骤5：处理下一组记录   29021.3.6  步骤6：考虑在节点2处分裂   29221.3.7  步骤7：处理下一组记录   29221.3.8  H-Tree算法概述   29321.4  分裂属性：使用信息增益   29521.5  分裂属性：使用Hoeffding边界   29721.6  H-Tree算法：*终版本   30021.7  使用不断进化的H-Tree进行预测   30221.8  实验：H-Tree与TDIDT   30421.8.1  lens24数据集   30421.8.2  vote数据集   30621.9  本章小结   30721.10  自我评估练习   307第 22 章  分类流数据II：时间相关数据   30922.1  平稳数据与时间相关数据   30922.2  H-Tree算法总结   31122.2.1  currentAtts数组   31222.2.2  splitAtt数组   31222.2.3  hitcount数组   31222.2.4  classtotals数组   31222.2.5  acvCounts数组   31322.2.6  branch数组   31322.2.7  H-Tree算法的伪代码   31322.3  从H-Tree到CDH-Tree：概述   31522.4  从H-Tree转换到CDH-Tree：递增计数   31522.5  滑动窗口法   31622.6  在节点处重新分裂   32022.7  识别可疑节点   32022.8  创建备用节点   32222.9  成长/遗忘备用节点及其后代   32522.10  用备用节点替换一个内部节点   32722.11  实验：跟踪概念漂移   33322.11.1  lens24数据：替代模式   33522.11.2  引入概念漂移   33522.11.3  使用交替lens24数据的实验   33622.11.4  关于实验的评论   34322.12  本章小结   34322.13  自我评估练习   343附录 A  基本数学知识   345附录 B  数据集   357附录 C  更多信息来源   371附录 D  词汇表和符号   373附录 E  自我评估练习题答案   391参考文献   419
